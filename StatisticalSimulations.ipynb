{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Ran Meng\n",
    "\n",
    "This jupyter notebook contains my work for certification of \"Statistical Simulation in Python\" instructed by Tushar Shanker of Uber, from [DataCamp](https://learn.datacamp.com/courses/statistical-simulation-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poisson random variable\n",
    "\n",
    "The numpy.random module also has a number of useful probability distributions for both discrete and continuous random variables. In this exercise, you will learn how to draw samples from a probability distribution.\n",
    "\n",
    "In particular, you will draw samples from a very important discrete probability distribution, the Poisson distribution, which is typically used for modeling the average rate at which events occur.\n",
    "\n",
    "Following the exercise, you should be able to apply these steps to any of the probability distributions found in numpy.random. In addition, you will also see how the sample mean changes as we draw more samples from a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Lambda - sample mean| with 3 samples is 0.33333333333333304 and with 1000 samples is 0.07699999999999996. \n"
     ]
    }
   ],
   "source": [
    "# Initialize seed and parameters\n",
    "np.random.seed(123) \n",
    "lam, size_1, size_2 = 5, 3, 1000  \n",
    "\n",
    "# Draw samples & calculate absolute difference between lambda and sample mean\n",
    "samples_1 = np.random.poisson(lam, size_1)\n",
    "samples_2 = np.random.poisson(lam, size_2)\n",
    "answer_1 = abs(lam - np.mean(samples_1))\n",
    "answer_2 = abs(lam - np.mean(samples_2)) \n",
    "\n",
    "print(\"|Lambda - sample mean| with {} samples is {} and with {} samples is {}. \".format(size_1, answer_1, size_2, answer_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling a deck of cards\n",
    "\n",
    "Often times we are interested in randomizing the order of a set of items. Consider a game of cards where you first shuffle the deck of cards or a game of scrabble where the letters are first mixed in a bag. As the final exercise of this section, you will learn another useful function - **np.random.shuffle()**. This function allows you to randomly shuffle a sequence in place. At the end of this exercise, you will know how to shuffle a deck of cards or any sequence of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck_of_cards = [('Heart', 0),\n",
    " ('Heart', 1),\n",
    " ('Heart', 2),\n",
    " ('Heart', 3),\n",
    " ('Heart', 4),\n",
    " ('Heart', 5),\n",
    " ('Heart', 6),\n",
    " ('Heart', 7),\n",
    " ('Heart', 8),\n",
    " ('Heart', 9),\n",
    " ('Heart', 10),\n",
    " ('Heart', 11),\n",
    " ('Heart', 12),\n",
    " ('Club', 0),\n",
    " ('Club', 1),\n",
    " ('Club', 2),\n",
    " ('Club', 3),\n",
    " ('Club', 4),\n",
    " ('Club', 5),\n",
    " ('Club', 6),\n",
    " ('Club', 7),\n",
    " ('Club', 8),\n",
    " ('Club', 9),\n",
    " ('Club', 10),\n",
    " ('Club', 11),\n",
    " ('Club', 12),\n",
    " ('Spade', 0),\n",
    " ('Spade', 1),\n",
    " ('Spade', 2),\n",
    " ('Spade', 3),\n",
    " ('Spade', 4),\n",
    " ('Spade', 5),\n",
    " ('Spade', 6),\n",
    " ('Spade', 7),\n",
    " ('Spade', 8),\n",
    " ('Spade', 9),\n",
    " ('Spade', 10),\n",
    " ('Spade', 11),\n",
    " ('Spade', 12),\n",
    " ('Diamond', 0),\n",
    " ('Diamond', 1),\n",
    " ('Diamond', 2),\n",
    " ('Diamond', 3),\n",
    " ('Diamond', 4),\n",
    " ('Diamond', 5),\n",
    " ('Diamond', 6),\n",
    " ('Diamond', 7),\n",
    " ('Diamond', 8),\n",
    " ('Diamond', 9),\n",
    " ('Diamond', 10),\n",
    " ('Diamond', 11),\n",
    " ('Diamond', 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Spade', 11), ('Heart', 10), ('Diamond', 1)]\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(deck_of_cards)\n",
    "\n",
    "# Print out the top three cards\n",
    "card_choices_after_shuffle = deck_of_cards[:3]\n",
    "print(card_choices_after_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Throwing a fair die\n",
    "\n",
    "Once you grasp the basics of designing a simulation, you can apply it to any system or process. Next, we will learn how each step is implemented using some basic examples.\n",
    "\n",
    "As we have learned, simulation involves repeated random sampling. The first step then is to get one random sample. Once we have that, all we do is repeat the process multiple times. This exercise will focus on understanding how we get one random sample. We will study this in the context of throwing a fair six-sided die.\n",
    "\n",
    "By the end of this exercise, you will be familiar with how to implement the first two steps of running a simulation - defining a random variable and assigning probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome of the throw: 1\n"
     ]
    }
   ],
   "source": [
    "# Define die outcomes and probabilities\n",
    "die, probabilities,throws = [1,2,3,4,5,6], [1/6,1/6,1/6,1/6,1/6,1/6], 1\n",
    "\n",
    "# Use np.random.choice to throw the die once and record the outcome\n",
    "outcome = np.random.choice(die, size=throws, p=probabilities)\n",
    "print(\"Outcome of the throw: {}\".format(outcome[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Throwing two fair dice\n",
    "\n",
    "We now know how to implement the first two steps of a simulation. Now let's implement the next step - defining the relationship between random variables.\n",
    "\n",
    "Often times, our simulation will involve not just one, but multiple random variables. Consider a game where you throw two dice and win if each die shows the same number. Here we have two random variables - the two dice - and a relationship between each of them - we win if they show the same number, lose if they don't. In reality, the relationship between random variables can be much more complex, especially when simulating things like weather patterns.\n",
    "\n",
    "By the end of this exercise, you will be familiar with how to implement the third step of running a simulation - defining relationships between random variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3]\n",
      "The dice show 4 and 3. You lose!\n"
     ]
    }
   ],
   "source": [
    "# Initialize number of dice, simulate & record outcome\n",
    "die, probabilities, num_dice = [1,2,3,4,5,6], [1/6, 1/6, 1/6, 1/6, 1/6, 1/6], 2\n",
    "outcomes = np.random.choice(die, size=num_dice, p=probabilities) \n",
    "\n",
    "# Win if the two dice show the same number\n",
    "if outcomes[0] == outcomes[1]: \n",
    "    answer = 'win' \n",
    "else:\n",
    "    answer = 'lose'\n",
    "print(outcomes)\n",
    "print(\"The dice show {} and {}. You {}!\".format(outcomes[0], outcomes[1], answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating the dice game\n",
    "\n",
    "We now know how to implement the first three steps of a simulation. Now let's consider the next step - repeated random sampling.\n",
    "\n",
    "Simulating an outcome once doesn't tell us much about how often we can expect to see that outcome. In the case of the dice game from the previous exercise, it's great that we won once. But suppose we want to see how many times we can expect to win if we played this game multiple times, we need to repeat the random sampling process many times. Repeating the process of random sampling is helpful to understand and visualize inherent uncertainty and deciding next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 100 games, you win 21 times\n"
     ]
    }
   ],
   "source": [
    "# Initialize model parameters & simulate dice throw\n",
    "die, probabilities, num_dice = [1,2,3,4,5,6], [1/6, 1/6, 1/6, 1/6, 1/6, 1/6], 2\n",
    "sims, wins = 100, 0\n",
    "\n",
    "for i in range(sims):\n",
    "    outcomes = np.random.choice(die, p = probabilities, size = num_dice) \n",
    "    # Increment `wins` by 1 if the dice show same number\n",
    "    if outcomes[0] == outcomes[1]: \n",
    "        wins = wins + 1 \n",
    "\n",
    "print(\"In {} games, you win {} times\".format(sims, wins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulating one lottery drawing**\n",
    "\n",
    "In the last three exercises of this chapter, we will be bringing together everything you've learned so far. We will run a complete simulation, take a decision based on our observed outcomes, and learn to modify inputs to the simulation model.\n",
    "\n",
    "We will use simulations to figure out whether or not we want to buy a lottery ticket. Suppose you have the opportunity to buy a lottery ticket which gives you a shot at a grand prize of \\\\$10,000. Since there are 1000 tickets in total, your probability of winning is 1 in 1000. Each ticket costs \\$10. Let's use our understanding of basic simulations to first simulate one drawing of the lottery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome of one drawing of the lottery is [-10]\n"
     ]
    }
   ],
   "source": [
    "# Pre-defined constant variables\n",
    "lottery_ticket_cost, num_tickets, grand_prize = 10, 1000, 1000000\n",
    "\n",
    "# Probability of winning\n",
    "chance_of_winning = 1/num_tickets\n",
    "\n",
    "# Simulate a single drawing of the lottery\n",
    "gains = [-lottery_ticket_cost, grand_prize-lottery_ticket_cost]\n",
    "probability = [1-chance_of_winning, chance_of_winning]\n",
    "outcome = np.random.choice(a=gains, size=1, p=probability, replace=True)\n",
    "\n",
    "print(\"Outcome of one drawing of the lottery is {}\".format(outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average payoff from 2000 simulations = 490.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize size and simulate outcome\n",
    "lottery_ticket_cost, num_tickets, grand_prize = 10, 1000, 1000000\n",
    "chance_of_winning = 1/num_tickets\n",
    "size = 2000\n",
    "payoffs = [-lottery_ticket_cost, grand_prize - lottery_ticket_cost]\n",
    "probs = [1-chance_of_winning, chance_of_winning]\n",
    "\n",
    "outcomes = np.random.choice(a=payoffs, size=size, p=probs, replace=True)\n",
    "\n",
    "# Mean of outcomes.\n",
    "answer = np.mean(outcomes)\n",
    "print(\"Average payoff from {} simulations = {}\".format(size, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating a break-even lottery price\n",
    "\n",
    "Simulations allow us to ask more nuanced questions that might not necessarily have an easy analytical solution. Rather than solving a complex mathematical formula, we directly get multiple sample outcomes. We can run experiments by modifying inputs and studying how those changes impact the system. For example, once we have a moderately reasonable model of global weather patterns, we could evaluate the impact of increased greenhouse gas emissions.\n",
    "\n",
    "In the lottery example, we might want to know how expensive the ticket needs to be for it to not make sense to buy it. To understand this, we need to modify the ticket cost to see when the expected payoff is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest price at which it makes sense to buy the ticket is 12\n"
     ]
    }
   ],
   "source": [
    "# Initialize simulations and cost of ticket\n",
    "sims, lottery_ticket_cost = 3000, 0\n",
    "\n",
    "# Use a while loop to increment `lottery_ticket_cost` till average value of outcomes falls below zero\n",
    "while 1:\n",
    "    outcomes = np.random.choice([-lottery_ticket_cost, grand_prize-lottery_ticket_cost],\n",
    "                 size=sims, p=[1-chance_of_winning, chance_of_winning], replace=True)\n",
    "    if outcomes.mean() < 0:\n",
    "        break\n",
    "    else:\n",
    "        lottery_ticket_cost += 1\n",
    "answer = lottery_ticket_cost - 1\n",
    "\n",
    "print(\"The highest price at which it makes sense to buy the ticket is {}\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two of a kind\n",
    "\n",
    "Now let's use simulation to estimate probabilities. Suppose you've been invited to a game of poker at your friend's home. In this variation of the game, you are dealt five cards and the player with the better hand wins. You will use a simulation to estimate the probabilities of getting certain hands. Let's work on estimating the probability of getting at least two of a kind. Two of a kind is when you get two cards of different suites but having the same numeric value (e.g., 2 of hearts, 2 of spades, and 3 other cards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of seeing at least two of a kind = 0.4907 \n"
     ]
    }
   ],
   "source": [
    "# Shuffle deck & count card occurrences in the hand\n",
    "n_sims, two_kind = 10000, 0\n",
    "for i in range(n_sims):\n",
    "    np.random.shuffle(deck_of_cards)\n",
    "    hand, cards_in_hand = deck_of_cards[0:5], {'Heart':0, 'Club':0, 'Spade':0, 'Diamond':0}\n",
    "    for card in hand:\n",
    "        #print(card)\n",
    "        # Use .get() method on cards_in_hand\n",
    "        cards_in_hand[card[1]] = cards_in_hand.get(card[1], 0) + 1 #0 is the optional argument, A value to return if the specified key does not exist.\n",
    "    # Condition for getting at least 2 of a kind\n",
    "    highest_card = max(cards_in_hand.values())\n",
    "    if highest_card>=2: \n",
    "        two_kind += 1\n",
    "\n",
    "print(\"Probability of seeing at least two of a kind = {} \".format(two_kind/n_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heart': 0,\n",
       " 'Club': 0,\n",
       " 'Spade': 0,\n",
       " 'Diamond': 0,\n",
       " 5: 1,\n",
       " 2: 1,\n",
       " 10: 1,\n",
       " 9: 1,\n",
       " 12: 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_in_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game of thirteen\n",
    "\n",
    "A famous French mathematician Pierre Raymond De Montmart, who was known for his work in combinatorics, proposed a simple game called as Game of Thirteen. You have a deck of 13 cards, each numbered from 1 through 13. Shuffle this deck and draw cards one by one. A coincidence is when the number on the card matches the order in which the card is drawn. For instance, if the 5th card you draw happens to be a 5, it's a coincidence. You win the game if you get through all the cards without any coincidences. Let's calculate the probability of winning at this game using simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of winning = 0.36129999999999995\n"
     ]
    }
   ],
   "source": [
    "# Pre-set constant variables\n",
    "deck, sims, coincidences = np.arange(1, 14), 10000, 0\n",
    "\n",
    "for _ in range(sims):\n",
    "    # Draw all the cards without replacement to simulate one game\n",
    "    draw = np.random.choice(deck, size= 13, replace=False)\n",
    "    # Check if there are any coincidences\n",
    "    coincidence = (draw == list(np.arange(1, 14))).any()\n",
    "    if coincidence == 1: \n",
    "        coincidences += 1\n",
    "\n",
    "# Calculate probability of winning\n",
    "prob_of_winning = 1 - coincidences/sims\n",
    "print(\"Probability of winning = {}\".format(prob_of_winning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The conditional urn\n",
    "As we've learned, conditional probability is defined as the probability of an event given another event. To illustrate this concept, let's turn to an urn problem.\n",
    "\n",
    "We have an urn that contains 7 white and 6 black balls. Four balls are drawn at random. We'd like to know the probability that the first and third balls are white, while the second and the fourth balls are black.\n",
    "\n",
    "Upon completion, you will learn to manipulate simulations to calculate simple conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of success = 0.0728\n"
     ]
    }
   ],
   "source": [
    "# Initialize success, sims and urn\n",
    "success, sims = 0, 5000\n",
    "urn = ['w','w','w','w','w','w','w','b','b','b','b','b','b']\n",
    "\n",
    "for _ in range(sims):\n",
    "    # Draw 4 balls without replacement\n",
    "    draw = np.random.choice(urn, replace=False, size=4)\n",
    "    # Count the number of successes\n",
    "    if draw[0] == 'w' and draw[2] == 'w' and draw[1] == 'b' and draw[3] == 'b': \n",
    "        success +=1\n",
    "\n",
    "print(\"Probability of success = {}\".format(success/sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birthday problem\n",
    "\n",
    "Now we'll use simulation to solve a famous probability puzzle - the birthday problem. It sounds quite straightforward - How many people do you need in a room to ensure at least a 50% chance that two of them share the same birthday?\n",
    "\n",
    "With 366 people in a 365-day year, we are 100% sure that at least two have the same birthday, but we only need to be 50% sure. Simulation gives us an elegant way of solving this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a sample of birthdays & check if each birthday is unique\n",
    "days = range(1,366)\n",
    "people = 2\n",
    "\n",
    "def birthday_sim(people):\n",
    "    sims, unique_birthdays = 2000, 0 \n",
    "    for _ in range(sims):\n",
    "        draw = np.random.choice(days, size= people, replace=True)\n",
    "        if len(draw) == len(set(draw)): \n",
    "            unique_birthdays += 1\n",
    "    out = 1 - unique_birthdays / sims\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 23 people, there's a 50% chance that two share a birthday.\n"
     ]
    }
   ],
   "source": [
    "# Break out of the loop if probability greater than 0.5\n",
    "while (people > 0):\n",
    "    prop_bds = birthday_sim(people)\n",
    "    if prop_bds > 0.5: \n",
    "        break\n",
    "    people += 1\n",
    "\n",
    "print(\"With {} people, there's a 50% chance that two share a birthday.\".format(people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of seeing a full house = 0.0008\n"
     ]
    }
   ],
   "source": [
    "n_sims, full_house  = 10000, 0\n",
    "\n",
    "#Shuffle deck & count card occurrences in the hand\n",
    "for i in range(n_sims):\n",
    "    np.random.shuffle(deck_of_cards)\n",
    "    hand, cards_in_hand = deck_of_cards[0:5], {}\n",
    "    for card in hand:\n",
    "        # Use .get() method to count occurrences of each card\n",
    "        cards_in_hand[card[1]] = cards_in_hand.get(card[1], 0) + 1\n",
    "    # Condition for getting full house\n",
    "    condition = (max(cards_in_hand.values()) ==3) & (min(cards_in_hand.values())==2)\n",
    "    if condition: \n",
    "        full_house += 1\n",
    "print(\"Probability of seeing a full house = {}\".format(full_house/n_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driving test\n",
    "\n",
    "Through the next exercises, we will learn how to build a data generating process (DGP) through progressively complex examples.\n",
    "\n",
    "In this exercise, you will simulate a very simple DGP. Suppose that you are about to take a driving test tomorrow. Based on your own practice and based on data you have gathered, you know that the probability of you passing the test is 90% when it's sunny and only 30% when it's raining. Your local weather station forecasts that there's a 40% chance of rain tomorrow. Based on this information, you want to know what is the probability of you passing the driving test tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims, outcomes, p_rain, p_pass = 1000, [], 0.40, {'sun':0.9, 'rain':0.3}\n",
    "\n",
    "def test_outcome(p_rain):\n",
    "    # Simulate whether it will rain or not\n",
    "    weather = np.random.choice(['rain', 'sun'], p=[p_rain, 1-p_rain])\n",
    "    # Simulate and return whether you will pass or fail\n",
    "    test_result = np.random.choice(['pass', 'fail'], p=[p_pass[weather], 1-p_pass[weather]])\n",
    "    return test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success = 0\n",
    "for i in range(sims):\n",
    "    success = success + 1 if test_outcome(0.4) == 'pass' else success\n",
    "\n",
    "success/sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### National elections\n",
    "\n",
    "This exercise will give you a taste of how you can model a DGP at different levels of complexity.\n",
    "\n",
    "Consider national elections in a country with two political parties - Red and Blue. This country has 50 states and the party that wins the most states wins the elections. You have the probability p of Red winning in each individual state and want to know the probability of Red winning nationally.\n",
    "\n",
    "Let's model the DGP to understand the distribution. Suppose the election outcome in each state follows a binomial distribution with probability p such that 0 indicates a loss for Red and 1 indicates a win. We then simulate a number of election outcomes. Finally, we can ask rich questions like **what is the probability of Red winning less than 45% of the states?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Red winning in less than 45% of the states = 0.19866666666666666\n"
     ]
    }
   ],
   "source": [
    "outcomes, sims, probs = [], 3000, p\n",
    "\n",
    "for _ in range(sims):\n",
    "    # Simulate elections in the 50 states\n",
    "    election = np.random.binomial(1, p = probs) #List of length 50\n",
    "    # Get average of Red wins and add to `outcomes`\n",
    "    outcomes.append(np.mean(election))\n",
    "\n",
    "# Calculate probability of Red winning in less than 45% of the states\n",
    "under_45 = [outcome for outcome in outcomes if outcome < 0.45]\n",
    "prob_red_wins = len(under_45)/len(outcomes)\n",
    "print(\"Probability of Red winning in less than 45% of the states = {}\".format(prob_red_wins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness goals\n",
    "\n",
    "Let's model how activity levels impact weight loss using modern fitness trackers. On days when you go to the gym, you average around 15k steps, and around 5k steps otherwise. You go to the gym 40% of the time. Let's model the step counts in a day as a Poisson random variable with a mean  dependent on whether or not you go to the gym.\n",
    "\n",
    "For simplicity, letâ€™s say you have an 80% chance of losing 1lb and a 20% chance of gaining 1lb when you get more than 10k steps. The probabilities are reversed when you get less than 8k steps. Otherwise, there's an even chance of gaining or losing 1lb. Given all this information, find the probability of losing weight in a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of losing weight in a month: 0.198\n"
     ]
    }
   ],
   "source": [
    "sims = 1000\n",
    "days = 30\n",
    "outcomes = []\n",
    "\n",
    "for sim in range(sims):\n",
    "    w_change_month = []\n",
    "    for i in range(days):\n",
    "        lam = np.random.choice([15000,5000], p = [0.4, 0.6])\n",
    "        step_count = np.random.poisson(lam)\n",
    "\n",
    "        if step_count > 10000:\n",
    "            w_change_day = np.random.choice([-1, 1], p = [0.8, 0.2])\n",
    "\n",
    "        elif step_count < 8000:\n",
    "            w_change_day = np.random.choice([1, -1], p = [0.8, 0.2])\n",
    "\n",
    "        else:\n",
    "            w_change_day = np.random.choice([-1, 1], p = [0.5, 0.5])\n",
    "\n",
    "        w_change_month.append(w_change_day)\n",
    "    outcome = sum(w_change_month)\n",
    "    outcomes.append(outcome)\n",
    "    \n",
    "weight_loss = [outcome for outcome in outcomes if outcome < 0]\n",
    "\n",
    "print('Probability of losing weight in a month: {0}'.format(len(weight_loss)/len(outcomes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sign up Flow\n",
    "\n",
    "We will now model the DGP of an eCommerce ad flow starting with sign-ups.\n",
    "\n",
    "On any day, we get many ad impressions, which can be modeled as Poisson random variables (RV). You are told that  is normally distributed with a mean of 100k visitors and standard deviation 2000.\n",
    "\n",
    "During the signup journey, the customer sees an ad, decides whether or not to click, and then whether or not to signup. Thus both clicks and signups are binary, modeled using binomial RVs. What about probability  of success? Our current low-cost option gives us a click-through rate of 1% and a sign-up rate of 20%. A higher cost option could increase the clickthrough and signup rate by up to 20%, but we are unsure of the level of improvement, so we model it as a uniform RV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Signups = [251]\n"
     ]
    }
   ],
   "source": [
    "# Initialize click-through rate and signup rate dictionaries\n",
    "ct_rate = {'low':0.01, 'high':np.random.uniform(low=0.01, high=1.2*0.01)}\n",
    "su_rate = {'low':0.2, 'high':np.random.uniform(low=0.2, high=1.2*0.2)}\n",
    "\n",
    "def get_signups(cost, ct_rate, su_rate, sims):\n",
    "    lam = np.random.normal(loc=100000, scale=2000, size=sims)\n",
    "    # Simulate impressions(poisson), clicks(binomial) and signups(binomial)\n",
    "    impressions = np.random.poisson(lam = lam)\n",
    "    #print(impressions)\n",
    "    clicks = np.random.binomial(n = impressions, p = ct_rate[cost])\n",
    "    #print(clicks)\n",
    "    signups = np.random.binomial(n = clicks, p = su_rate[cost])\n",
    "    #print(signups)\n",
    "    return signups\n",
    "\n",
    "print(\"Simulated Signups = {}\".format(get_signups('high', ct_rate, su_rate, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purchase Flow\n",
    "\n",
    "After signups, let's model the revenue generation process. Once the customer has signed up, they decide whether or not to purchase - a natural candidate for a binomial RV. Let's assume that 10% of signups result in a purchase.\n",
    "\n",
    "Although customers can make many purchases, let's assume one purchase. The purchase value could be modeled by any continuous RV, but one nice candidate is the exponential RV. Suppose we know that purchase value per customer has averaged around $1000. We use this information to create the purchase_values RV. The revenue, then, is simply the sum of all purchase values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Revenue = $20732.464083102146\n"
     ]
    }
   ],
   "source": [
    "def get_revenue(signups):\n",
    "    rev = []\n",
    "    np.random.seed(123)\n",
    "    #print(signups)\n",
    "    for s in signups:\n",
    "        #print(s)\n",
    "        # Model purchases as binomial, purchase_values as exponential\n",
    "        purchases = np.random.binomial(s, p=0.1) # returns # of successes\n",
    "        #print(purchases)\n",
    "        purchase_values = np.random.exponential(scale = 1000, size = purchases)\n",
    "        #print(purchase_values)\n",
    "        # Append to revenue the sum of all purchase values.\n",
    "        rev.append(sum(purchase_values))\n",
    "    return rev\n",
    "\n",
    "print(\"Simulated Revenue = ${}\".format(get_revenue(get_signups('low', ct_rate, su_rate, 1))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of losing money\n",
    "\n",
    "In this exercise, we will use the DGP model to estimate probability.\n",
    "\n",
    "As seen earlier, this company has the option of spending extra money, let's say \\\\$3000, to redesign the ad. This could potentially get them higher clickthrough and signup rates, but this is not guaranteed. We would like to know whether or not to spend this extra \\\\$3000 by calculating the probability of losing money. In other words, the probability that the revenue from the high-cost option minus the revenue from the low-cost option is lesser than the cost.\n",
    "\n",
    "Once we have simulated revenue outcomes, we can ask a rich set of questions that might not have been accessible using traditional analytical methods.\n",
    "\n",
    "This simple yet powerful framework forms the basis of Bayesian methods for getting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of losing money: 0.6346\n"
     ]
    }
   ],
   "source": [
    "sims = 10000\n",
    "cost_diff = 3000\n",
    "\n",
    "# Simulate revenues for both options\n",
    "rev_low = get_revenue(get_signups('low', ct_rate, su_rate, sims))\n",
    "rev_high = get_revenue(get_signups('low', ct_rate, su_rate, sims))\n",
    "\n",
    "# Calculate revenue difference and compare with difference in media cost\n",
    "diff = [high - low for high, low in zip(rev_high, rev_low)]\n",
    "\n",
    "# Calculate Probability of losing money\n",
    "loss = [d for d in diff if d < cost_diff]\n",
    "print('Probability of losing money: {}'.format(len(loss)/sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability example\n",
    "\n",
    "In this exercise, we will review the difference between sampling with and without replacement. We will calculate the probability of an event using simulation, but vary our sampling method to see how it impacts probability.\n",
    "\n",
    "Consider a bowl filled with colored candies - three blue, two green, and five yellow. Draw three candies, one at a time, with replacement and without replacement. You want to calculate the probability that **all three candies are yellow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability with replacement = 0.1273, without replacement = 0.083\n"
     ]
    }
   ],
   "source": [
    "# Set up the bowl\n",
    "success_rep, success_no_rep, sims = 0, 0, 10000\n",
    "bowl = ['b', 'b', 'b', 'g', 'g', 'y', 'y', 'y', 'y', 'y']\n",
    "\n",
    "for i in range(sims):\n",
    "    # Sample with and without replacement & increment success counters\n",
    "    sample_rep = np.random.choice(bowl, replace = True, size = 3)\n",
    "    sample_no_rep = np.random.choice(bowl, replace = False, size = 3)\n",
    "    if (sample_rep[0] == 'y') & (sample_rep[1] == 'y') & (sample_rep[2] == 'y'): \n",
    "        success_rep += 1\n",
    "    if (sample_no_rep[0] == 'y') & (sample_no_rep[1] == 'y') & (sample_no_rep[2] == 'y'): \n",
    "        success_no_rep += 1\n",
    "\n",
    "# Calculate probabilities\n",
    "prob_with_replacement = success_rep/sims\n",
    "prob_without_replacement = success_no_rep/sims\n",
    "print(\"Probability with replacement = {}, without replacement = {}\".format(prob_with_replacement, prob_without_replacement))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a simple bootstrap\n",
    "Welcome to the first exercise in the bootstrapping section. We will work through an example where we learn to run a simple bootstrap. As we saw in the video, the main idea behind bootstrapping is sampling with replacement.\n",
    "\n",
    "Suppose you own a factory that produces wrenches. You want to be able to characterize the average length of the wrenches and ensure that they meet some specifications. Your factory produces thousands of wrenches every day, but it's infeasible to measure the length of each wrench. However, you have access to a representative sample of 100 wrenches. Let's use bootstrapping to get the 95% confidence interval (CI) for the average lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped Mean Length = 10.027558762827601, 95% CI = [ 9.79760047 10.24205421]\n"
     ]
    }
   ],
   "source": [
    "# Draw some random sample with replacement and append mean to mean_lengths.\n",
    "mean_lengths, sims = [], 1000\n",
    "for i in range(sims):\n",
    "    temp_sample = np.random.choice(wrench_lengths, replace= True, size= len(wrench_lengths))\n",
    "    sample_mean = np.mean(temp_sample)\n",
    "    mean_lengths.append(sample_mean)\n",
    "    \n",
    "# Calculate bootstrapped mean and 95% confidence interval.\n",
    "boot_mean = np.mean(mean_lengths)\n",
    "boot_95_ci = np.percentile(mean_lengths, [2.5, 97.5])\n",
    "print(\"Bootstrapped Mean Length = {}, 95% CI = {}\".format(boot_mean, boot_95_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic jackknife estimation - mean\n",
    "\n",
    "Jackknife resampling is an older procedure, which isn't used as often compared as bootstrapping. However, it's still useful to know how to run a basic jackknife estimation procedure. In this first exercise, we will calculate the jackknife estimate for the mean. Let's return to the wrench factory.\n",
    "\n",
    "You own a wrench factory and want to measure the average length of the wrenches to ensure that they meet some specifications. Your factory produces thousands of wrenches every day, but it's infeasible to measure the length of each wrench. However, you have access to a representative sample of 100 wrenches. Let's use jackknife estimation to get the average lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife estimate of the mean = 10.027109074099998\n"
     ]
    }
   ],
   "source": [
    "# Leave one observation out from wrench_lengths to get the jackknife sample and store the mean length\n",
    "mean_lengths, n = [], len(wrench_lengths)\n",
    "index = np.arange(n)\n",
    "\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    mean_lengths.append(np.mean(jk_sample))\n",
    "\n",
    "# The jackknife estimate is the mean of the mean lengths from each sample\n",
    "mean_lengths_jk = np.mean(np.array(mean_lengths))\n",
    "print(\"Jackknife estimate of the mean = {}\".format(mean_lengths_jk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jackknife confidence interval for the median\n",
    "\n",
    "In this exercise, we will calculate the jackknife 95% CI for a non-standard estimator. Here, we will look at the median. Keep in mind that the variance of a jackknife estimator is n-1 times the variance of the individual jackknife sample estimates where n is the number of observations in the original sample.\n",
    "\n",
    "Returning to the wrench factory, you are now interested in estimating the median length of the wrenches along with a 95% CI to ensure that the wrenches are within tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife 95% CI lower = 9.138592415216381, upper = 10.754868124783625\n"
     ]
    }
   ],
   "source": [
    "# Leave one observation out to get the jackknife sample and store the median length\n",
    "median_lengths = []\n",
    "for i in range(n):\n",
    "    jk_sample = wrench_lengths[index != i]\n",
    "    median_lengths.append(np.median(jk_sample))\n",
    "\n",
    "median_lengths = np.array(median_lengths)\n",
    "\n",
    "# Calculate jackknife estimate and it's variance\n",
    "jk_median_length = np.mean(median_lengths)\n",
    "jk_var = (n-1)*np.var(median_lengths)\n",
    "\n",
    "# Assuming normality, calculate lower and upper 95% confidence intervals\n",
    "jk_lower_ci = jk_median_length - 1.96*np.sqrt(jk_var)\n",
    "jk_upper_ci = jk_median_length + 1.96*np.sqrt(jk_var)\n",
    "print(\"Jackknife 95% CI lower = {}, upper = {}\".format(jk_lower_ci, jk_upper_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a single permutation\n",
    "\n",
    "In the next few exercises, we will run a significance test using permutation testing. As discussed in the video, we want to see if there's any difference in the donations generated by the two designs - A and B. Suppose that you have been running both the versions for a few days and have generated 500 donations on A and 700 donations on B, stored in the variables donations_A and donations_B.\n",
    "\n",
    "We first need to generate a null distribution for the difference in means. We will achieve this by generating multiple permutations of the dataset and calculating the difference in means for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in the permuted mean values = 0.2349814109784889.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the two arrays donations_A and donations_B into data\n",
    "len_A, len_B = len(donations_A), len(donations_B)\n",
    "data = np.concatenate([donations_A, donations_B])\n",
    "\n",
    "# Get a single permutation of the concatenated length\n",
    "perm = np.random.permutation(len(donations_A) + len(donations_B))\n",
    "\n",
    "# Calculate the permutated datasets and difference in means\n",
    "permuted_A = data[perm[:len(donations_A)]]\n",
    "permuted_B = data[perm[len(donations_A):]]\n",
    "diff_in_means = np.mean(permuted_A) - np.mean(permuted_B)\n",
    "print(\"Difference in the permuted mean values = {}.\".format(diff_in_means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis testing - Difference of means\n",
    "\n",
    "We want to test the hypothesis that there is a difference in the average donations received from A and B. Previously, you learned how to generate one permutation of the data. Now, we will generate a null distribution of the difference in means and then calculate the **p-value**.\n",
    "\n",
    "For the null distribution, we first generate multiple permuted datasets and store the difference in means for each case. We then calculate the test statistic as the difference in means with the original dataset. Finally, we approximate the p-value by calculating twice the fraction of cases where the difference is greater than or equal to the absolute value of the test statistic (2-sided hypothesis). A p-value of less than say 0.05 could then determine statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value = 0.004\n"
     ]
    }
   ],
   "source": [
    "reps = 1000\n",
    "\n",
    "# Generate permutations equal to the number of repetitions\n",
    "perm = np.array([np.random.permutation(len(donations_A) + len(donations_B)) for i in range(reps)]) # 1000 * 1200 (500 + 700)\n",
    "permuted_A_datasets = data[perm[:, :len(donations_A)]] # 1000*500\n",
    "permuted_B_datasets = data[perm[:, len(donations_A):]] # 1000*700\n",
    "\n",
    "# Calculate the difference in means for each of the datasets\n",
    "samples = np.mean(permuted_A_datasets, axis = 1) - np.mean(permuted_B_datasets, axis = 1) # Get mean of the dataset for dataset in datasets\n",
    "\n",
    "# Calculate the test statistic and p-value\n",
    "test_stat = np.mean(donations_A) - np.mean(donations_B)\n",
    "p_val = 2*np.sum(samples >= np.abs(test_stat))/reps\n",
    "print(\"p-value = {}\".format(p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis testing - Non-standard statistics\n",
    "\n",
    "In the previous two exercises, we ran a permutation test for the difference in mean values. Now let's look at non-standard statistics.\n",
    "\n",
    "Suppose that you're interested in understanding the distribution of the donations received from websites A and B. For this, you want to see if there's a statistically significant difference in the median and the 80th percentile of the donations. Permutation testing gives you a wonderfully flexible framework for attacking such problems.\n",
    "\n",
    "Let's go through running a test to see if there's a difference in the median and the 80th percentile of the distribution of donations. As before, you're given the donations from the websites A and B in the variables donations_A and donations_B respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference in 80th percentile and median for each of the permuted datasets (A and B)\n",
    "samples_percentile = np.percentile(permuted_A_datasets, axis = 1, q = 80) - np.percentile(permuted_B_datasets, axis = 1, q = 80)\n",
    "samples_median = np.median(permuted_A_datasets, axis = 1) - np.median(permuted_B_datasets, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test statistic from the original dataset and corresponding p-values\n",
    "test_stat_percentile =  np.percentile(donations_A, 80) - np.percentile(donations_B, 80)\n",
    "test_stat_median = np.median(donations_A) - np.median(donations_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80th Percentile: test statistic = 1.6951624520000035, p-value = 0.038\n",
      "Median: test statistic = 0.6434965699999999, p-value = 0.016\n"
     ]
    }
   ],
   "source": [
    "p_val_percentile = 2*np.sum(samples_percentile >= np.abs(test_stat_percentile))/reps\n",
    "p_val_median = 2*np.sum(samples_median >= np.abs(test_stat_median))/reps\n",
    "\n",
    "print(\"80th Percentile: test statistic = {}, p-value = {}\".format(test_stat_percentile, p_val_percentile))\n",
    "print(\"Median: test statistic = {}, p-value = {}\".format(test_stat_median, p_val_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Corn Production\n",
    "Suppose that you manage a small corn farm and are interested in optimizing your costs. In this illustrative exercise, we will model the production of corn. We'll abstract away from details like units and focus on the process.\n",
    "\n",
    "For simplicity, let's assume that corn production depends on only two factors: rain, which you don't control, and cost, which you control. Rain is normally distributed with mean 50 and standard deviation 15. For now, let's fix cost at 5,000. Let's assume that corn produced in any season is a Poisson random variable and that the average corn production is governed by the equation:\n",
    "\n",
    "\n",
    "Let's model this production function and simulate one outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Corn Production = 507\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "cost = 5000\n",
    "rain = np.random.normal(50, 15)\n",
    "\n",
    "# Corn Production Model\n",
    "def corn_produced(rain, cost):\n",
    "    mean_corn = 100*(cost**0.1)*(rain**0.2)\n",
    "    corn = np.random.poisson(lam = mean_corn)\n",
    "    return corn\n",
    "\n",
    "# Simulate and print corn production\n",
    "corn_result = corn_produced(rain,cost)\n",
    "print(\"Simulated Corn Production = {}\".format(corn_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corn_demanded(price):\n",
    "    mean_corn = 1000 - 8*price\n",
    "    corn = np.random.poisson(abs(mean_corn))\n",
    "    return corn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling Profits\n",
    "\n",
    "In the previous exercise, you built a model of corn production. For a small farm, you typically have no control over the price or demand for corn. Suppose that price is normally distributed with mean 40 and standard deviation 10. You are given a function corn_demanded(), which takes the price and determines the demand for corn. This is reasonable because demand is usually determined by the market and is not in your control.\n",
    "\n",
    "In this exercise, you will work on a function to calculate the profit by pulling together all the other simulated variables. The only input to this function will be the fixed cost of production. Upon completion, you'll have a function that gives one simulated profit outcome for a given cost. This function can then be used for planning your costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated profit = 13295.200078443075\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate profits\n",
    "def profits(cost):\n",
    "    rain = np.random.normal(50, 15)\n",
    "    price = np.random.normal(40, 10)\n",
    "    supply = corn_produced(rain,cost)\n",
    "    demand = corn_demanded(price)\n",
    "    equil_short = supply <= demand\n",
    "    if equil_short:\n",
    "        tmp = supply*price - cost\n",
    "        return tmp\n",
    "    else: \n",
    "        tmp2 = demand*price - cost\n",
    "        return tmp2\n",
    "result = profits(cost)\n",
    "print(\"Simulated profit = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Costs\n",
    "\n",
    "Now we will use the functions you've built to optimize our cost of production. We are interested in maximizing average profits. However, our profits depend on a number of factors, while we only control cost. Thus, we can simulate the uncertainty in the other factors and vary cost to see how our profits are impacted.\n",
    "\n",
    "Since you manage the small corn farm, you have the ability to choose your cost - from \\\\$100 to \\\\$5,000. You want to choose the cost that gives you the maximum average profit. In this exercise, we will simulate multiple outcomes for each cost level and calculate an average. We will then choose the cost that gives us the maximum mean profit. Upon completion, you will have a framework for selecting optimal inputs for business decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\242\\lib\\site-packages\\ipykernel_launcher.py:8: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average profit is maximized when cost = 1700\n"
     ]
    }
   ],
   "source": [
    "# Initialize results and cost_levels variables\n",
    "sims, results = 1000, {}\n",
    "cost_levels = np.arange(100, 5100, 100)\n",
    "\n",
    "# For each cost level, simulate profits and store mean profit\n",
    "for cost in cost_levels:\n",
    "    tmp_profits = []\n",
    "    for i in range(sims):\n",
    "        tmp_profits.append(profits(cost))\n",
    "    results[cost] = np.mean(tmp_profits)\n",
    "    \n",
    "# Get the cost that maximizes average profit\n",
    "cost_max = [x for x in results.keys() if results[x] == max(results.values())][0]\n",
    "print(\"Average profit is maximized when cost = {}\".format(cost_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrating a Simple Function\n",
    "This is a simple exercise introducing the concept of Monte Carlo Integration.\n",
    "\n",
    "Here we will evaluate a simple integral \n",
    "\n",
    "\n",
    "We know that the exact answer is , but simulation will give us an approximate solution, so we can expect an answer close to . As we saw in the video, it's a simple process. For a function of a single variable :\n",
    "\n",
    "Get the limits of the x-axis(X<sub>min</sub>, X<sub>max</sub>)  and y-axis (max(f(x)), min(min(f(x), 0)).\n",
    "\n",
    "Generate a number of uniformly distributed point in this box.\n",
    "\n",
    "Multiply the area of the box ((max(f(x)) - min(f(x))) * (X<sub>min</sub> - X<sub>max</sub>)) by the fraction of points that lie below f(x).\n",
    "\n",
    "Upon completion, you will have a framework for handling definite integrals using Monte Carlo Integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated answer = 0.999168811590039, Actual Answer = 1\n"
     ]
    }
   ],
   "source": [
    "# Define the sim_integrate function\n",
    "def sim_integrate(func, xmin, xmax, sims):\n",
    "    x = np.random.uniform(xmin, xmax, sims)\n",
    "    y = np.random.uniform(min(min(func(x)), 0), max(func(x)), sims)\n",
    "    area = (max(y) - min(y))*(xmax-xmin)\n",
    "    result = area * sum(abs(y) < abs(func(x)))/sims\n",
    "    return result\n",
    "    \n",
    "# Call the sim_integrate function and print results\n",
    "result = sim_integrate(func = lambda x: x*np.exp(x), xmin = 0, xmax = 1, sims = 50000)\n",
    "print(\"Simulated answer = {}, Actual Answer = 1\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the value of pi\n",
    "\n",
    "Now we work through a classic example - estimating the value of $\\pi$.\n",
    "\n",
    "Imagine a square of side 2 with the origin (0,0) as its center and the four corners having coordinates (-1,-1), (-1,1), (1,1), (1,-1) . The area of this square is 2 X 2 = 4. Now imagine a circle of radius 1 with its center at the origin fitting perfectly inside this square. The area of the circle will be $\\pi$.\n",
    "\n",
    "To estimate , we randomly sample multiple points in this square & get the fraction of points inside the circle (\n",
    "$x^2+y^2 = 1$). The area of the circle then is 4 times this fraction, which gives us our estimate of $\\pi$.\n",
    "\n",
    "After this exercise, you'll have a grasp of how to use simulation for computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated value of pi = 3.134\n"
     ]
    }
   ],
   "source": [
    "# Initialize sims and circle_points\n",
    "sims, circle_points = 10000, 0 \n",
    "\n",
    "for i in range(sims):\n",
    "    # Generate the two coordinates of a point\n",
    "    point = np.random.uniform(low = -1, high = 1, size = 2)\n",
    "    # if the point lies within the unit circle, increment counter\n",
    "    within_circle = point[0]**2 + point[1]**2 <= 1\n",
    "    if within_circle:\n",
    "        circle_points +=1\n",
    "        \n",
    "# Estimate pi as 4 times the avg number of points in the circle.\n",
    "pi_sim = 4*circle_points/sims\n",
    "print(\"Simulated value of pi = {}\".format(pi_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Analysis - Part I\n",
    "\n",
    "Now we turn to power analysis. You typically want to ensure that any experiment or A/B test you run has at least 80% power. One way to ensure this is to calculate the sample size required to achieve 80% power.\n",
    "\n",
    "Suppose that you are in charge of a news media website and you are interested in increasing the amount of time users spend on your website. Currently, the time users spend on your website is normally distributed with a mean of 1 minute and a standard deviation of 0.5 minutes. Suppose that you are introducing a feature that loads pages faster and want to know the sample size required to measure a 5% increase in time spent on the website.\n",
    "\n",
    "In this exercise, we will set up the framework to run one simulation, run a t-test, & calculate the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13463358899440617\n",
      "P-value: 0.8931777075650447, Statistically Significant? False\n"
     ]
    }
   ],
   "source": [
    "# Initialize effect_size, control_mean, control_sd\n",
    "effect_size, sample_size, control_mean, control_sd = 0.05, 50, 1, 0.5\n",
    "\n",
    "# Simulate control_time_spent and treatment_time_spent, assuming equal variance\n",
    "control_time_spent = np.random.normal(loc=control_mean, scale=control_sd, size=sample_size)\n",
    "treatment_time_spent = np.random.normal(loc=control_mean*(1+effect_size), scale=control_sd, size=sample_size)\n",
    "\n",
    "# Run the t-test and get the p_value\n",
    "t_stat, p_value = st.ttest_ind(treatment_time_spent, control_time_spent)\n",
    "print(t_stat)\n",
    "stat_sig = p_value < 0.05\n",
    "print(\"P-value: {}, Statistically Significant? {}\".format(p_value, stat_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power Analysis - Part II\n",
    "\n",
    "Previously, we simulated one instance of the experiment & generated a p-value. We will now use this framework to calculate statistical power. Power of an experiment is the experiment's ability to detect a difference between treatment & control if the difference really exists. It's good statistical hygiene to strive for 80% power.\n",
    "\n",
    "For our website, suppose we want to know how many people need to visit each variant, such that we can detect a 10% increase in time spent with 80% power. For this, we start with a small sample (50), simulate multiple instances of this experiment & check power. If 80% power is reached, we stop. If not, we increase the sample size & try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 80% power, sample size required = 1550\n"
     ]
    }
   ],
   "source": [
    "sims = 1000\n",
    "sample_size = 50\n",
    "# Keep incrementing sample size by 10 till we reach required power\n",
    "while 1:\n",
    "    control_time_spent = np.random.normal(loc=control_mean, scale=control_sd, size=(sample_size, sims))\n",
    "    treatment_time_spent = np.random.normal(loc=control_mean*(1+effect_size), scale=control_sd, size=(sample_size, sims))\n",
    "    t, p = st.ttest_ind(treatment_time_spent, control_time_spent)\n",
    "    \n",
    "    # Power is the fraction of times in the simulation when the p-value was less than 0.05\n",
    "    power = (p < 0.05).sum()/sims\n",
    "    if power >= 0.8: \n",
    "        break\n",
    "    else: \n",
    "        sample_size += 10\n",
    "print(\"For 80% power, sample size required = {}\".format(sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio Simulation - Part I\n",
    "\n",
    "In the next few exercises, you will calculate the expected returns of a stock portfolio & characterize its uncertainty.\n",
    "\n",
    "Suppose you have invested $10,000 in your portfolio comprising of multiple stocks. You want to evaluate the portfolio's performance over 10 years. You can tweak your overall expected rate of return and volatility (standard deviation of the rate of return). Assume the rate of return follows a normal distribution.\n",
    "\n",
    "First, let's write a function that takes the principal (initial investment), number of years, expected rate of return and volatility as inputs and returns the portfolio's total value after 10 years.\n",
    "\n",
    "Upon completion of this exercise, you will have a function you can call to determine portfolio performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio return after 5 years = 1193.6477486736817\n"
     ]
    }
   ],
   "source": [
    "# rates is a Normal random variable and has size equal to number of years\n",
    "def portfolio_return(yrs, avg_return, sd_of_return, principal):\n",
    "    rates = np.random.normal(loc=avg_return, scale=sd_of_return, size=yrs)\n",
    "    # Calculate the return at the end of the period\n",
    "    end_return = principal\n",
    "    for x in rates:\n",
    "        end_return = (1+x)*end_return\n",
    "    return end_return\n",
    "\n",
    "result = portfolio_return(yrs = 5, avg_return = 0.07, sd_of_return = 0.15, principal = 1000)\n",
    "print(\"Portfolio return after 5 years = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio Simulation - Part II\n",
    "\n",
    "Now we will use the simulation function you built to evaluate 10-year returns.\n",
    "\n",
    "Your stock-heavy portfolio has an initial investment of \\\\$10,000, an expected return of 7% and a volatility of 30%. You want to get a 95% confidence interval of what your investment will be worth in 10 years. We will simulate multiple samples of 10-year returns and calculate the confidence intervals on the distribution of returns.\n",
    "\n",
    "By the end of this exercise, you will have run a complete portfolio simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI of Returns: Lower = 1454.429990891001, Upper = 77113.102303189\n"
     ]
    }
   ],
   "source": [
    "# Run 1,000 iterations and store the results\n",
    "sims, rets = 1000, []\n",
    "\n",
    "for i in range(sims):\n",
    "    rets.append(portfolio_return(yrs = 10, avg_return = 0.07, \n",
    "                                 sd_of_return = 0.3, principal = 10000))\n",
    "\n",
    "# Calculate the 95% CI\n",
    "lower_ci = np.percentile(rets, q = 2.5)\n",
    "upper_ci = np.percentile(rets, q = 97.5)\n",
    "print(\"95% CI of Returns: Lower = {}, Upper = {}\".format(lower_ci, upper_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio Simulation - Part III\n",
    "\n",
    "Previously, we ran a complete simulation to get a distribution for 10-year returns. Now we will use simulation for decision making.\n",
    "\n",
    "Let's go back to your stock-heavy portfolio with an expected return of 7% and a volatility of 30%. You have the choice of rebalancing your portfolio with some bonds such that the expected return is 4% & volatility is 10%. You have a principal of $10,000. You want to select a strategy based on how much your portfolio will be worth in 10 years. Let's simulate returns for both the portfolios and choose based on the least amount you can expect with 75% probability (25th percentile).\n",
    "\n",
    "Upon completion, you will know how to use a portfolio simulation for investment decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sticking to stocks gets you an additional return of -4928.6786747273945\n"
     ]
    }
   ],
   "source": [
    "rets_stock = []\n",
    "rets_bond = []\n",
    "\n",
    "for i in range(sims):\n",
    "    rets_stock.append(portfolio_return(yrs = 10, avg_return = 0.07, sd_of_return = 0.3, principal = 10000))\n",
    "    rets_bond.append(portfolio_return(yrs = 10, avg_return = 0.04, sd_of_return = 0.1, principal = 10000))\n",
    "\n",
    "# Calculate the 25th percentile of the distributions and the amount you'd lose or gain\n",
    "rets_stock_perc = np.percentile(rets_stock, q = 25)\n",
    "rets_bond_perc = np.percentile(rets_bond, q = 25)\n",
    "additional_returns = rets_stock_perc - rets_bond_perc\n",
    "print(\"Sticking to stocks gets you an additional return of {}\".format(additional_returns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
